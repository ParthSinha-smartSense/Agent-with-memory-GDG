# OpenAI API Configuration
OPENAI_API_KEY=your_openai_api_key_here

# Ollama Configuration (Local AI Models)
# Make sure Ollama is installed and running: ollama serve
# Popular models: llama3.2, llama3.1, mistral, codellama, qwen2.5, phi3
# Default Ollama endpoint: http://localhost:11434
OLLAMA_HOST=http://localhost:11434

# LLM Model Configuration
MODEL_NAME=gpt-4.1-mini
SMALL_MODEL_NAME=gpt-4.1-nano
LLM_TEMPERATURE=0.0

# Embedder Configuration
EMBEDDER_MODEL_NAME=text-embedding-3-small

# Neo4j Database Configuration (adjust as needed)
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=password

# Azure OpenAI Configuration (optional, uncomment if using Azure)
# AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
# AZURE_OPENAI_API_VERSION=2024-02-15-preview
# AZURE_OPENAI_DEPLOYMENT_NAME=your-deployment-name
# AZURE_OPENAI_USE_MANAGED_IDENTITY=false

# Azure OpenAI Embedding Configuration (optional)
# AZURE_OPENAI_EMBEDDING_ENDPOINT=https://your-resource.openai.azure.com/
# AZURE_OPENAI_EMBEDDING_API_VERSION=2024-02-15-preview
# AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME=your-embedding-deployment
# AZURE_OPENAI_EMBEDDING_API_KEY=your_azure_embedding_api_key

# MCP Server Configuration
MCP_SERVER_HOST=127.0.0.1
SEMAPHORE_LIMIT=10